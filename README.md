<!--
SEO Keywords: multi-agent AI, AI orchestration, LangGraph agents, agent framework,
real-time AI dashboard, AI mission control, autonomous agents, LLM orchestration,
AI agent metrics, agent workflow, LangChain multi-agent, GPT-4 agents, agentic AI,
AI workflow automation, agent observability, AI team collaboration, FastAPI agents,
Next.js AI dashboard, real-time agent monitoring, AI agent visualization
-->

# Commander.ai

> **Mission Control for your AI team.** Watch specialized agents collaborate in real-time, executing complex tasks with complete visibility and maximum control.

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![Next.js](https://img.shields.io/badge/Next.js-14-black.svg)](https://nextjs.org/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Latest-green.svg)](https://github.com/langchain-ai/langgraph)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)

[![GitHub Stars](https://img.shields.io/github/stars/iotlodge/commander.ai?style=social)](https://github.com/iotlodge/commander.ai/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/iotlodge/commander.ai?style=social)](https://github.com/iotlodge/commander.ai/network/members)
[![GitHub Issues](https://img.shields.io/github/issues/iotlodge/commander.ai)](https://github.com/iotlodge/commander.ai/issues)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)

</div>

---

## ğŸ¯ Why Commander.ai?

**Single AI assistants give you one perspective. Commander.ai gives you a specialized team you can tune in real-time.**

Unlike chatbots that force you to wait and guess, Commander.ai shows you **exactly what's happening** as your AI team worksâ€”and lets you **engineer their behavior on the fly**:

- ğŸ”´ **Live Agent Activity** - Watch tokens flow and LLM calls execute in real-time
- ğŸ§  **Live Prompt Engineering** - Edit agent prompts, test with real LLM, see instant results âœ¨ **NEW in v0.3.0**
- âš¡ **One-Click Commands** - Quick Actions panel for instant delegation
- ğŸ“Š **Complete Visibility** - See every node, tool call, and decision
- ğŸ¯ **Maximum Control** - Clear completed tasks, zoom agent graphs, filter by agent
- ğŸš€ **True Parallelization** - Multiple agents working simultaneously

**This isn't a chat interface with agents bolted on. It's Mission Control with a prompt engineering workshop built in.**

<div align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="images/dark_landing_page.png">
    <source media="(prefers-color-scheme: light)" srcset="images/light_landing_page.png">
    <img alt="Commander.ai Mission Control" src="images/dark_landing_page.png" width="100%">
  </picture>
  <p><em>Mission Control: Real-time visibility into your AI team</em></p>
</div>

---

## ğŸ•¹ï¸ Mission Control Interface

### Three-Panel Command Center

**Left Panel: AI Agents**
- 7 specialized agents with real-time metrics
- Live token counts, LLM calls, tool usage
- Current processing node ("â†’ reasoning...")
- Active/queued task indicators
- System activity dashboard

**Center Panel: Conversation Stream**
- Chronological command/response flow
- Expandable metrics & execution flow
- Inline agent graph visualization with zoom
- Smooth, stable rendering (no animations to distract)

**Right Panel: Quick Actions**
- One-click pre-configured commands
- Organized by agent specialty
- Auto-fills command input
- Examples:
  - ğŸ“„ Alice: "List all documents", "Archive old files"
  - ğŸ” Bob: "Latest AI news", "Market research"
  - ğŸ“Š Rex: "Analyze data", "Generate report"

![Live Agent Metrics](images/actve_agent_updates.png)
*Agent tiles showing real-time token counts, LLM calls, and current processing node*

![Multi-Agent Conversation Flow](images/mult-conversation_with_flow.png)
*Multiple agents working in parallel with complete execution visibility*

### Real-Time Visibility

**Watch Your Agents Work:**
```
@kai (Reflexion Specialist)
ğŸŸ¢ 1 active
1,234 tok | 3 LLM | 2 tools | â†’ reasoning
```

Every agent tile updates live as they:
- Consume tokens (green counter)
- Make LLM calls (purple counter)
- Use tools (yellow counter)
- Progress through workflow nodes (blue text)

**Completed Task Tracking:**
- "Done" counter in System Activity
- "Clear Completed" button (only shows when needed)
- Confirmation before clearing
- Keeps conversation focused on active work

![Metrics & Flow](images/sequence_and_metrics.png)
*Expandable metrics showing tokens, LLM calls, tool calls, duration, and step-by-step execution timeline*

### Agent Interaction

**Single-Click Agent Selection:**
- Click any agent tile â†’ Auto-fills command input with `@agent `
- Instant delegation - just add your task and press Enter
- Example: Click @bob â†’ type "latest AI news" â†’ Send

**Multi-Select with Modifier Keys:**
- Hold **âŒ˜ (Command)** or **Shift** while clicking agents
- Build multi-agent commands effortlessly
- Example workflow:
  ```
  1. Click @bob â†’ "@bob "
  2. Hold âŒ˜ + Click @alice â†’ "@bob @alice "
  3. Hold Shift + Click @kai â†’ "@bob @alice @kai "
  4. Add task: "research and document quantum computing"
  5. Send â†’ @leo orchestrates all three agents
  ```

**Smart Command Routing:**
- **Single @mention** â†’ Direct to that agent
- **Multiple @mentions** â†’ @leo orchestrates the team
- **No @mention** â†’ Defaults to @leo

*ğŸ’¡ Tip: Look for the hint "Hold âŒ˜ / Shift to select multiple agents" in the Agent Panel*

---

## ğŸ¤– Meet Your AI Team

### ğŸ’¬ @chat - Interactive Chat Assistant
Your conversational interface with live web search.
- GPT-4o-mini for natural conversations
- **Automatic web search** when you ask current questions
- Agentic tool execution loop
- Context-aware responses

### ğŸ”¬ @bob - Research Specialist
Deep research with multi-source synthesis.
- Tavily web search + LLM analysis
- Automatic compliance flagging
- 24h cache for general queries, 1h for news
- *Your investigative journalist*

### âš–ï¸ @sue - Compliance Specialist
Keep your projects legally sound.
- GDPR, HIPAA, data protection review
- Regulatory compliance analysis
- Risk assessment and policy checks
- *Your legal safeguard*

### ğŸ“Š @rex - Data Analyst
Turn numbers into insights.
- Statistical analysis and visualization
- Pattern detection and trend analysis
- Matplotlib chart generation
- *Your data scientist*

### ğŸ“š @alice - Document Manager
Semantic document search and storage.
- PDF processing with OCR
- **Web search â†’ persistent storage**
- Vector embeddings via Qdrant
- Collection management (create/delete/search)
- *Your librarian with superpowers*

### âœ¨ @maya - Reflection Specialist
Quality control through critique.
- Content review with severity ratings
- Issue identification (critical/important/minor)
- Generates improved versions
- Quality scoring (0-1.0)
- *Your editor and QA team*

### ğŸ”„ @kai - Reflexion Specialist
Iterative reasoning through self-reflection.
- Up to 3 self-improvement cycles
- Shows reasoning evolution
- Self-critique and refinement
- *Your deep thinker*

![Kai in Action](images/kai1.png)
*@kai executing reflexive reasoning with full execution trace*

---

## ğŸ§  Live Prompt Engineering - **NEW in v0.3.0**

### **Tune Your AI Team's Intelligence in Real-Time**

**The breakthrough**: You're not stuck with pre-programmed agent behavior. Commander.ai v0.3.0 introduces **live prompt engineering**â€”edit how your agents think, test changes instantly, and optimize AI orchestration outcomes on the fly.

### ğŸ›ï¸ **What You Can Do**

**Access the Workshop:**
- Hover over any agent card
- Click the âš™ï¸ Settings icon
- Enter the Prompt Management UI

![Agent Settings Icon](images/agent_system_settings.png)
*Hover over any agent card to reveal the âš™ï¸ Settings icon. Click to access Prompt Management.*

**Inside the Prompt Engineer:**

1. **ğŸ“‹ Browse & Search**
   - View all prompts for the selected agent
   - Search by keyword across descriptions and prompt text
   - Filter by type (system, human, ai) and active status
   - See creation/update timestamps

![Manage Prompts Modal](images/manage_prompt_modal.png)
*Prompt List Modal showing search, filters, and prompt cards with type badges, active status, and update timestamps.*

2. **âœï¸ Create & Edit**
   - Write new prompts with rich template variables
   - Edit existing prompts while preserving version history
   - Add dynamic variables: `{query}`, `{token_budget}`, `{urgency}`, `{tools_list}`
   - Toggle active/inactive for A/B testing

![Edit Prompt Interface](images/edit_live_prompts.png)
*Prompt Editor with description, prompt text area, template variables section, and Test button for live LLM validation.*

3. **ğŸ§ª Test with Real LLM**
   - Click "Test" on any prompt
   - Enter a test query
   - See **live GPT-4o-mini response** with your custom prompt
   - View performance metrics:
     - Response time (ms)
     - Token usage (prompt + completion)
     - Total cost estimation
   - Debug compiled messages (system + user prompts)

4. **ğŸ”„ Iterate & Optimize**
   - See results instantly
   - Compare prompt variations
   - Measure impact on token efficiency
   - Optimize for speed vs. quality

### ğŸ¨ **Visual Workflow**

The prompt engineering interface follows an intuitive three-step process:

1. **Access** - Hover over any agent â†’ Click âš™ï¸ Settings
2. **Browse** - Search/filter prompts â†’ View details â†’ Click Edit
3. **Edit & Test** - Modify prompt â†’ Add variables â†’ Test with GPT-4o-mini â†’ Save

Each step is designed for speed and clarity, making prompt optimization feel natural.

### ğŸ’¡ **Why This Changes Everything**

**Before v0.3.0:**
- Agent behavior was hardcoded
- Tuning required backend changes and redeployment
- No way to test prompt modifications
- One-size-fits-all approach

**With v0.3.0 Prompt Engineering:**
- âœ… Tune agents **without touching code**
- âœ… Test prompts **with real LLM** before activating
- âœ… See metrics: tokens, time, cost
- âœ… A/B test different approaches (toggle active/inactive)
- âœ… Dynamic variables adapt to task context
- âœ… Version history tracks all changes

### ğŸ¯ **Real-World Use Cases**

**Scenario 1: Reduce Token Usage**
```
Problem: @bob uses too many tokens for simple queries
Solution:
  1. Open @bob's prompts
  2. Edit system prompt to be more concise
  3. Test with "latest AI news"
  4. Compare tokens: 1,234 â†’ 856 (31% reduction!)
  5. Activate optimized prompt
```

**Scenario 2: Improve Response Quality**
```
Problem: @maya's reflections lack depth
Solution:
  1. Clone existing system prompt
  2. Add: "Provide 3 specific examples for each issue"
  3. Test with sample content
  4. See richer, more actionable feedback
  5. Switch to new prompt
```

**Scenario 3: Task-Specific Behavior**
```
Problem: Need @alice to prioritize speed over accuracy for demos
Solution:
  1. Create new "demo_mode" prompt
  2. Add variable: {mode} = "demo" | "production"
  3. Adjust system instructions for speed
  4. Test and activate for demos
  5. Switch back to production mode after
```

### ğŸš€ **The Meta-Programming Advantage**

You're not just using AIâ€”you're **engineering how AI thinks**.

- **Frontend teams** can optimize agent behavior without backend deploys
- **Prompt engineers** can iterate 10x faster with live testing
- **Product teams** can A/B test different agent personalities
- **Operations** can tune for cost vs. performance in real-time

**This is the workshop that turns Commander.ai from a tool into a platform.**

---

## ğŸš€ Quick Start

### One-Command Setup

```bash
# 1. Clone and configure
git clone https://github.com/iotlodge/commander.ai.git
cd commander.ai
cp .env.example .env
# Add your OPENAI_API_KEY and TAVILY_API_KEY to .env

# 2. Start infrastructure (PostgreSQL, Redis, Qdrant)
docker-compose up -d

# 3. Backend
uv sync                    # or: pip install -r requirements.txt
alembic upgrade head
python -m uvicorn backend.api.main:app --reload

# 4. Frontend (new terminal)
cd frontend && npm install && npm run dev

# 5. Open Mission Control
open http://localhost:3000
```

**That's it.** You're in the command center.

---

## ğŸ’¬ Command Examples

### Natural Delegation

```bash
# Quick questions with live web search
@chat what's the latest news about AI safety?

# Deep research
@bob research quantum computing breakthroughs in 2026

# Compliance review
@sue review this privacy policy for GDPR compliance

# Data analysis
@rex analyze sales trends from last quarter

# Document management
@alice search web for "climate change reports" into research_collection

# Quality assurance
@maya review this code for potential issues

# Complex problem solving
@kai solve: how can we reduce API latency by 50%?
```

### Quick Actions (One-Click)

Click any Quick Action button to auto-fill commands:
- **Alice**: "List all documents" â†’ `@alice list all documents in the system`
- **Bob**: "Latest AI news" â†’ `@bob what's the latest news in AI?`
- **Rex**: "Generate report" â†’ `@rex generate a detailed analytical report on`

Edit the command, add context, hit Enter. Done.

---

## ğŸ“Š Performance & Intelligence System

**Commander.ai learns and optimizes agent performance automatically.**

The system tracks, evaluates, and routes tasks intelligently using:

- **ğŸ¯ Multi-Perspective Scoring** - Objective metrics, LLM self-assessment, peer reviews, user feedback, category performance
- **ğŸ† Reward System** - Gamification with bonuses/penalties based on quality, efficiency, speed, and innovation
- **ğŸ¤– Peer Evaluation** - Agents (Kai + Maya) review each other's work for continuous improvement
- **ğŸ§  Intelligent Routing** - Auto-classify tasks and select best agent based on historical performance
- **ğŸ“ˆ Real-Time Stats** - Aggregated performance data drives routing decisions (~$0.001/task for full intelligence)

**ğŸ“˜ [Complete Performance System Guide â†’](PERFORMANCE_SYSTEM_GUIDE.md)**

Learn how to monitor, tune, and optimize the entire intelligence layer built across Phases 1-3.

---

## ğŸ—ï¸ Architecture

### Tech Stack

**Backend (Python 3.12+)**
- **LangGraph** - Agent workflow orchestration
- **FastAPI** - High-performance async API
- **PostgreSQL** - Persistent storage with pgvector
- **Redis** - Hot memory layer (sessions)
- **Qdrant** - Vector database (semantic search)
- **OpenAI** - GPT-4o-mini + ada-002 embeddings
- **Tavily** - Web search API

**Frontend (TypeScript)**
- **Next.js 14** - App Router with React Server Components
- **Tailwind CSS** - Utility-first styling
- **shadcn/ui** - Accessible component library
- **Zustand** - Lightweight state management
- **WebSocket** - Real-time agent updates

### Three-Tier Memory System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redis       â”‚ â† Hot Layer (active conversations)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL  â”‚ â† Warm Layer (conversation history)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Qdrant      â”‚ â† Smart Layer (semantic search)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Every conversation persists. Every insight is searchable. Agents can recall past knowledge and build on previous work.

### Project Structure

```
commander.ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base/              # Agent interface & registry
â”‚   â”‚   â””â”€â”€ specialized/       # 8 specialist agents
â”‚   â”‚       â”œâ”€â”€ parent/        # @leo (Orchestrator)
â”‚   â”‚       â”œâ”€â”€ agent_a/       # @bob (Research)
â”‚   â”‚       â”œâ”€â”€ agent_b/       # @sue (Compliance)
â”‚   â”‚       â”œâ”€â”€ agent_c/       # @rex (Data Analysis)
â”‚   â”‚       â”œâ”€â”€ agent_d/       # @alice (Documents)
â”‚   â”‚       â”œâ”€â”€ agent_e/       # @maya (Reflection)
â”‚   â”‚       â”œâ”€â”€ agent_f/       # @kai (Reflexion)
â”‚   â”‚       â””â”€â”€ agent_g/       # @chat (Chat Assistant)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ prompt_engineer.py # ğŸ§  NEW - Dynamic prompt compilation & testing
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â””â”€â”€ prompt_repository.py # Database access for prompts
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ prompt_models.py    # Pydantic schemas for prompts
â”‚   â”œâ”€â”€ memory/               # Document store & embeddings
â”‚   â”œâ”€â”€ tools/                # Web search, data analysis, PDF processing
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ routes/
â”‚           â””â”€â”€ prompts.py    # ğŸ§  NEW - REST API for prompt management
â””â”€â”€ frontend/
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ mission-control/  # Three-panel UI
    â”‚   â”‚   â”œâ”€â”€ agent-team-panel.tsx      # Live agent metrics + âš™ï¸ Settings
    â”‚   â”‚   â”œâ”€â”€ conversation-stream.tsx   # Command/response flow
    â”‚   â”‚   â”œâ”€â”€ quick-actions-panel.tsx   # One-click commands
    â”‚   â”‚   â”œâ”€â”€ inline-execution-flow.tsx # Metrics timeline
    â”‚   â”‚   â””â”€â”€ inline-agent-graph.tsx    # Workflow visualization
    â”‚   â””â”€â”€ prompt-management/  # ğŸ§  NEW - Prompt Engineering UI
    â”‚       â”œâ”€â”€ prompt-list-modal.tsx     # Browse & search prompts
    â”‚       â”œâ”€â”€ prompt-editor-modal.tsx   # Create/edit prompts
    â”‚       â”œâ”€â”€ prompt-test-modal.tsx     # Live LLM testing
    â”‚       â””â”€â”€ prompt-card.tsx           # Individual prompt display
    â”œâ”€â”€ lib/
    â”‚   â””â”€â”€ hooks/
    â”‚       â””â”€â”€ use-prompts.ts  # ğŸ§  NEW - Prompt CRUD operations
    â””â”€â”€ app/                  # Next.js routes
```

---

## ğŸ“Š Execution Metrics & Observability

### What You See in Real-Time

**Agent Tiles (Live Updates):**
- Token consumption as agents work
- LLM call counts
- Tool usage (web search, data analysis, etc.)
- Current workflow node
- Active/queued task status

**Metrics & Flow (Per Task):**
```
Total Tokens: 1,234
â”œâ”€ 800 prompt + 434 completion

LLM Calls: 3
Tool Calls: 2
Duration: 12.4s

Execution Flow (5 steps):
â”œâ”€ 1. parse_input         [210ms]
â”œâ”€ 2. fetch_web           [8.2s] 856 tokens
â”œâ”€ 3. chunk_and_embed     [2.1s] 362 tokens
â”œâ”€ 4. store_chunks        [890ms]
â””â”€ 5. format_response     [45ms]
```

**System Activity Dashboard:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Active  â”‚ Queued  â”‚  Done   â”‚
â”‚   2     â”‚   1     â”‚   5     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[âœ“ Clear Completed (5)]
```

**Complete visibility.** No black boxes. See exactly what's happening.

---

## ğŸ”§ Adding a New Agent

Commander.ai is designed for extensibility. Add your own specialist in 5 steps:

### 1. Create Agent Directory
```bash
mkdir -p backend/agents/specialized/agent_h
cd backend/agents/specialized/agent_h
touch __init__.py graph.py state.py nodes.py
```

### 2. Define State
```python
# state.py
from typing import TypedDict

class MyAgentState(TypedDict):
    query: str
    user_id: str
    results: list[str]
    error: str | None
```

### 3. Implement Nodes
```python
# nodes.py
async def process_query_node(state: MyAgentState) -> dict:
    # Your logic here
    return {**state, "results": ["processed"]}
```

### 4. Build Graph
```python
# graph.py
from langgraph.graph import StateGraph, END
from backend.agents.base.agent_interface import BaseAgent, AgentMetadata

class MyAgent(BaseAgent):
    def __init__(self):
        super().__init__(AgentMetadata(
            id="agent_h",
            nickname="vision",  # @vision in UI
            specialization="Image Analysis",
            description="Analyzes images and extracts insights"
        ))

    def create_graph(self) -> StateGraph:
        graph = StateGraph(MyAgentState)
        graph.add_node("process", process_query_node)
        graph.set_entry_point("process")
        graph.add_edge("process", END)
        return graph
```

### 5. Register
```python
# backend/agents/base/agent_registry.py
from backend.agents.specialized.agent_h.graph import MyAgent

_registry["agent_h"] = MyAgent()
```

**Done.** Your agent appears in Mission Control with live metrics, Quick Actions integration, and full observability.

---

## âš™ï¸ Configuration

### Required Environment Variables

```bash
# Core (Required)
OPENAI_API_KEY=sk-...      # GPT-4o-mini + embeddings
TAVILY_API_KEY=tvly-...    # Web search

# Database (Auto-configured by docker-compose)
DATABASE_URL=postgresql+asyncpg://commander:changeme@localhost:5432/commander_ai
REDIS_URL=redis://localhost:6379/0
QDRANT_URL=http://localhost:6333

# Optional Tuning
WEB_CACHE_TTL_HOURS=24          # General content cache
WEB_CACHE_NEWS_TTL_HOURS=1       # News content cache
TAVILY_RATE_LIMIT_PER_MINUTE=60  # API rate limit
```

### Docker Services

```bash
docker-compose up -d
```

Starts PostgreSQL 16 (with pgvector), Redis 7, and Qdrant with health checks and auto-restart.

---

## ğŸš¦ Production Status

**âœ… v0.3.0 - Live Prompt Engineering** (February 2026) ğŸ”¥ **MAJOR RELEASE**

**ğŸ§  Revolutionary New Feature:**
- âœ… **Live Prompt Engineering** - Edit, test, and optimize agent behavior in real-time
  - Full CRUD for agent prompts via UI
  - Live LLM testing with GPT-4o-mini
  - Performance metrics (tokens, time, cost)
  - Template variables for dynamic context
  - A/B testing with active/inactive toggles
  - Search, filter, and version tracking
  - âš™ï¸ Settings icon on every agent card

**Core Features (Stable):**
- âœ… **Mission Control UI** - Three-panel interface with real-time metrics
- âœ… **8 Specialized Agents** - Leo (orchestrator), Chat, Research, Compliance, Data, Documents, Reflection, Reflexion
- âœ… **Quick Actions Panel** - One-click command delegation
- âœ… **Live Agent Metrics** - Token counts, LLM calls, tool usage, current node
- âœ… **Execution Flow Tracking** - Complete observability into every step
- âœ… **Graph Visualization** - Agent workflow diagrams with zoom controls
- âœ… **Completed Task Management** - Track and clear finished work
- âœ… **Light/Dark Mode** - Theme toggle with system preference detection
- âœ… **Three-Tier Memory** - Redis/PostgreSQL/Qdrant
- âœ… **Web Search Cache** - 24h general, 1h news TTL
- âœ… **JWT Authentication** - Production-ready security (94% test coverage)
- âœ… **DocumentStore Singleton** - Prevents connection pool exhaustion
- âœ… **Agentic Tool Execution** - Chat agent executes web searches automatically

**What's New in v0.3.0:**
- ğŸ§  **PROMPT ENGINEERING WORKSHOP** - The game-changer
  - In-UI prompt editor with live testing
  - Real GPT-4o-mini responses with metrics
  - Template variables: `{query}`, `{token_budget}`, `{urgency}`
  - Search across 10+ seeded prompts
  - No backend deploy needed for tuning
- ğŸ”§ **PromptEngineer Service** - Backend architecture for dynamic prompt compilation
- ğŸ“Š **Prompt Testing API** - `/api/prompts/test` with full metrics
- ğŸ¨ **Nested Modal System** - Browse â†’ Edit â†’ Test workflow
- ğŸ” **Prompt Search** - Find and filter prompts by agent, type, keywords

**Previous Releases:**
- **v0.2.0** (Feb 5, 2026) - Light/dark mode, agent status indicators, Leo orchestrator UI
- **v0.1.0** (Feb 1, 2026) - Mission Control UI, 7 agents, real-time metrics

**Roadmap:**
- ğŸ“… **Prompt Marketplace** - Share and discover optimized prompts
- ğŸ“… **Agent Integration** - Auto-use PromptEngineer for all agent initialization
- ğŸ“… **Cost Analytics** - Track prompt efficiency and ROI
- ğŸ“… **Vision Agent** - Image analysis and generation
- ğŸ“… **CLI Interface** - Terminal workflows for power users
- ğŸ“… **Code Execution** - Sandboxed Python/JS agents
- ğŸ“… **Plugin System** - Custom tools and integrations
- ğŸ“… **Enterprise SSO** - SAML/OAuth integration

---

## ğŸ¬ Getting Started Video

*(Coming soon - walkthrough of Mission Control interface, agent delegation, and Quick Actions)*

---

## ğŸ¤ Contributing

We're building the future of AI collaboration. Join us!

**Ways to Contribute:**
- ğŸ› Report bugs or UX improvements
- ğŸ’¡ Suggest new agent specializations
- ğŸ“ Improve documentation
- ğŸ§ª Add test coverage
- âš¡ Performance optimizations
- ğŸ¨ UI/UX enhancements

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“œ License

Apache License 2.0 - Commercial use, modification, distribution, and patent use allowed.

See [LICENSE](LICENSE) for full details.

---

## ğŸ™ Built With

- **[LangGraph](https://github.com/langchain-ai/langgraph)** - Agent orchestration framework
- **[LangChain](https://github.com/langchain-ai/langchain)** - LLM integration layer
- **[shadcn/ui](https://ui.shadcn.com/)** - Beautiful, accessible components
- **[Tavily](https://tavily.com/)** - Fast, reliable web search API
- **OpenAI** - GPT-4o-mini powers the intelligence

---

## ğŸ’¬ Why Mission Control?

Most AI tools hide what's happening. You ask, you wait, you hope.

**Commander.ai shows you everything:**
- Which agent is working
- What node they're on
- How many tokens they're using
- What tools they're calling
- How long it's taking

**You're not just using AI. You're commanding it.**

Try it. Watch @bob research while @alice stores results. See @maya catch issues before @kai refines the solution. Command, observe, control.

---

**Questions? Ideas? Issues?**

ğŸ“§ [Open an issue](https://github.com/iotlodge/commander.ai/issues)
â­ Star the repo if this excites you
ğŸ”” Watch for updates - we ship fast

---

*Built by developers who believe AI should augment human capability, not replace it.*

**ğŸš€ Status**: v0.3.0 Production - Live Prompt Engineering
**ğŸ“… Last Updated**: February 6, 2026
